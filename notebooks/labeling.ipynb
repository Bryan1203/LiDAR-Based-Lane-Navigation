{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pptk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load point cloud  \n",
    "# points = np.load(r\"D:\\484_final_project\\processed_point_cloud\\slam05_mapping_global.npy\")\n",
    "points = np.load(\"/media/kevin/X9 Pro/484_final_project/processed_point_cloud/slam11_mapping_global.npy\")\n",
    "# xyz = points[:, :, :3]\n",
    "# intensity = points[:,:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568, 128, 1024, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_005 = np.load('slam03_predictions_005.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_01 = np.load('slam03_predictions_01.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.load(\"/media/kevin/X9 Pro/484_final_project/processed_point_cloud/slam11_predictions.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ir = np.load(\"/media/kevin/X9 Pro/484_final_project/processed_point_cloud/slam11_near_ir_predictions.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681, 131072)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# point cloud has shape (frames, channels, points, attributes)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the viewer with intensity as the color\n",
    "frame = 0\n",
    "frame_end = 10\n",
    "u = pptk.viewer(points[frame:frame_end,:,:,:3])\n",
    "u.attributes(\n",
    "             points[frame:frame_end,:,:,3].flatten(), #reflectivity\n",
    "             points[frame:frame_end,:,:,4].flatten(), #ranges\n",
    "             points[frame:frame_end,:,:,5].flatten(), #signal\n",
    "             points[frame:frame_end,:,:,6].flatten(), # near ir\n",
    "            #  points[frame:frame_end,:,:,6].flatten()*median_scaling,\n",
    "            #  predictions_005*100000\n",
    "             predictions[frame:frame_end,:].flatten()*100000,\n",
    "            #  predictions_005[frame:frame_end,:].flatten()*100000\n",
    "            #  predictions_01[frame:frame_end,:].flatten()*100000\n",
    "             )\n",
    "u.set(point_size = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.color_map('jet', scale = [0,12520])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.color_map('jet', scale = [0,6532])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.set(point_size = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_intensities = points[frame:frame_end,:,:,6].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_intensities = points_0[frame:frame_end,:,:,6].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6803.8356315762385"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(reference_intensities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling factor: 5.408\n",
      "Original mean - Reference: 6803.836, Target: 1258.144\n",
      "Scaled mean - Reference: 6803.836, Scaled Target: 6803.836\n",
      "Original max - Reference: 65535.000, Target: 65535.000\n",
      "Scaled max - Reference: 65535.000, Scaled Target: 354402.483\n"
     ]
    }
   ],
   "source": [
    "# Get scaling factor using different methods\n",
    "mean_scaling = get_scaling_factor(reference_intensities, target_intensities, method='mean')\n",
    "median_scaling = get_scaling_factor(reference_intensities, target_intensities, method='median')\n",
    "\n",
    "# Apply the scaling factor\n",
    "normalized_intensities = target_intensities * mean_scaling\n",
    "\n",
    "# Evaluate the results\n",
    "evaluate_scaling(reference_intensities, target_intensities, mean_scaling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.407835244411551"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681.4610427856445"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(points[frame:frame_end,:,:,6].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.load(r\"C:\\Users\\Bryan\\Desktop\\cs411\\pred.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131072,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "u.set(point_size = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the selcted points (run this to save the current progress)\n",
    "selected_laneline = u.get('selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the label array with shape of points in a single frame 128 x 1024 \n",
    "lane_line_label = np.zeros_like(points[frame:frame+35, :, :, 4].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_labels = len(lane_line_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_labels//35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resume the selected lines on pptk viewer (optional)\n",
    "u.set(selected = selected_laneline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the label array with the selected_laneline\n",
    "lane_line_label[selected_laneline] = 1\n",
    "# create a label folder if you have not\n",
    "# np.save(f'label/lane_line_label_{frame}', lane_line_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lane_line_label.reshape(35,131072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4587520,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lane_line_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = 131072\n",
    "for i in range(35):\n",
    "    # Calculate start and end indices\n",
    "    start_idx = i * split_size\n",
    "    end_idx = start_idx + split_size\n",
    "    \n",
    "    # Extract the chunk\n",
    "    chunk = lane_line_label[start_idx:end_idx]\n",
    "    \n",
    "    # Save to file\n",
    "    np.save(f'label/label_{i:02d}.npy', chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_scaling_factor(reference_array, target_array, method='mean'):\n",
    "    \"\"\"\n",
    "    Calculate a single scaling factor to normalize target array to reference array.\n",
    "    \n",
    "    Parameters:\n",
    "    reference_array: np.array - The reference intensity values (recorded in first condition)\n",
    "    target_array: np.array - The intensity values to be normalized (recorded in second condition)\n",
    "    method: str - Method to calculate scaling factor ('mean', 'median', 'max', 'percentile')\n",
    "    \n",
    "    Returns:\n",
    "    float - Scaling factor to multiply with target array\n",
    "    \"\"\"\n",
    "    if method == 'mean':\n",
    "        # Use mean ratio\n",
    "        scaling_factor = np.mean(reference_array) / np.mean(target_array)\n",
    "    \n",
    "    elif method == 'median':\n",
    "        # Use median ratio (more robust to outliers)\n",
    "        scaling_factor = np.median(reference_array) / np.median(target_array)\n",
    "    \n",
    "    elif method == 'max':\n",
    "        # Use maximum value ratio\n",
    "        scaling_factor = np.max(reference_array) / np.max(target_array)\n",
    "    \n",
    "    elif method == 'percentile':\n",
    "        # Use 95th percentile ratio (robust to extreme outliers)\n",
    "        scaling_factor = (np.percentile(reference_array, 95) / \n",
    "                         np.percentile(target_array, 95))\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Method must be one of: 'mean', 'median', 'max', 'percentile'\")\n",
    "        \n",
    "    return scaling_factor\n",
    "\n",
    "# Function to evaluate the scaling\n",
    "def evaluate_scaling(reference_array, target_array, scaling_factor):\n",
    "    \"\"\"Print statistics about the scaling results\"\"\"\n",
    "    scaled_array = target_array * scaling_factor\n",
    "    \n",
    "    print(f\"Scaling factor: {scaling_factor:.3f}\")\n",
    "    print(f\"Original mean - Reference: {np.mean(reference_array):.3f}, Target: {np.mean(target_array):.3f}\")\n",
    "    print(f\"Scaled mean - Reference: {np.mean(reference_array):.3f}, Scaled Target: {np.mean(scaled_array):.3f}\")\n",
    "    print(f\"Original max - Reference: {np.max(reference_array):.3f}, Target: {np.max(target_array):.3f}\")\n",
    "    print(f\"Scaled max - Reference: {np.max(reference_array):.3f}, Scaled Target: {np.max(scaled_array):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.7279547694442986\n",
      "Precision: 0.6218831734960767\n",
      "Shape compatibility: True\n",
      "Value range check: True\n",
      "Value range check: True\n",
      "\n",
      "Confusion Matrix:\n",
      "TP: 249655, FP: 151795\n",
      "FN: 93299, TN: 88765283\n",
      "\n",
      "F1 Score: 0.670751366193626\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inference_points = np.load('/media/kevin/X9 Pro/484_final_project/processed_point_cloud/slam10_predictions.npy').flatten()\n",
    "# inference_points = inference_points[:,:, 3]\n",
    "ground_truth_points = np.load('/media/kevin/X9 Pro/484_final_project/processed_point_cloud/slam10_lane_line_label.npy').flatten()\n",
    "# ground_truth_points = ground_truth_points[:,:, 3]\n",
    "\n",
    "inference_positive_indices = inference_points ==1\n",
    "ground_truth_positive_indices = ground_truth_points ==1\n",
    "\n",
    "inference_negative_indices = inference_points ==0\n",
    "ground_truth_negative_indices = ground_truth_points ==0\n",
    "\n",
    "true_positive = np.sum(inference_positive_indices & ground_truth_positive_indices)\n",
    "false_positive = np.sum(inference_positive_indices & ground_truth_negative_indices)\n",
    "true_negative = np.sum(inference_negative_indices & ground_truth_negative_indices)\n",
    "false_negative = np.sum(inference_negative_indices & ground_truth_positive_indices)\n",
    "\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "\n",
    "print('Recall:', recall)\n",
    "print('Precision:', precision)\n",
    "\n",
    "# Add validation checks\n",
    "print('Shape compatibility:', inference_points.shape == ground_truth_points.shape)\n",
    "print('Value range check:', set(np.unique(inference_points)) <= {0,1})\n",
    "print('Value range check:', set(np.unique(ground_truth_points)) <= {0,1})\n",
    "\n",
    "# Print confusion matrix\n",
    "print('\\nConfusion Matrix:')\n",
    "print(f'TP: {true_positive}, FP: {false_positive}')\n",
    "print(f'FN: {false_negative}, TN: {true_negative}')\n",
    "\n",
    "# Add F1 score\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(f'\\nF1 Score: {f1_score}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pptk_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
